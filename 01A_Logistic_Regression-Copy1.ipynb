{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Logistic Regression in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange  # unnecessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is very popular machine learning dataset, consisting of 70000 grayscale images of handwritten digits, of dimensions 28x28. We'll be using it as our example for this section of the tutorial, with the goal being to predict which the digit is in each image.\n",
    "\n",
    "![mnist](Figures/mnist.png)\n",
    "\n",
    "Since it's such a common (and small) dataset, TensorFlow has commands for downloading and formatting the dataset conveniently baked in already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how the data is organized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image data: (55000, 784)\n",
      "Validation image data: (5000, 784)\n",
      "Testing image data: (10000, 784)\n",
      "28 x 28 = 784\n",
      "\n",
      "Test Labels: (10000, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Label distribution:[(0, 980), (1, 1135), (2, 1032), (3, 1010), (4, 982), (5, 892), (6, 958), (7, 1028), (8, 974), (9, 1009)]\n",
      "\n",
      "Train image 1 is labelled one-hot as [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x120d40e80>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset statistics\n",
    "print('Training image data: {0}'.format(mnist.train.images.shape)) ## 55,000 images, vectorized as one dimensional array \n",
    "print('Validation image data: {0}'.format(mnist.validation.images.shape))\n",
    "print('Testing image data: {0}'.format(mnist.test.images.shape))\n",
    "print('28 x 28 = {0}'.format(28*28))\n",
    "\n",
    "print('\\nTest Labels: {0}'.format(mnist.test.labels.shape))\n",
    "print(mnist.test.labels[0])  #a single one-hot list, represents 7\n",
    "\n",
    "labels = np.arange(10)\n",
    "num_labels = np.sum(mnist.test.labels, axis=0, dtype=np.int)\n",
    "print('Label distribution:{0}'.format(list(zip(labels,num_labels))))\n",
    "\n",
    "# Example image\n",
    "print('\\nTrain image 1 is labelled one-hot as {0}'.format(mnist.train.labels[1,:]))\n",
    "image = np.reshape(mnist.train.images[5,:], [28,28])\n",
    "plt.imshow(image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the graph input: this is where we feed in our training images into the model. Since MNIST digits are pretty small and the model we're using is very simple, we'll feed them in as flat vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784]) #none allows flexibility for mini batches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get our predicted probabilities of each digit, let's first start with the probability of a digit being a 3 like the image above. For our simple model, we start by applying a linear transformation. That is, we multiply each value of the input vector by a weight, sum them all together, and then add a bias. In equation form:\n",
    "\n",
    "\\begin{align}\n",
    "y_3 = \\sum_i w_{i,3} x_i + b_3\n",
    "\\end{align}\n",
    "\n",
    "The magnitude of this result $y_3$, we'll take as being correlated to our belief in how likely we think the input digit was a 3. The higher the value of $y_3$, the more likely we think the input image $x$ was a 3 (ie, we'd hope we'd get a relatively large value for $y_3$ for the above image). Remember though, our original goal was to identify all 10 digits, so we also have:\n",
    "\n",
    "\\begin{align*}\n",
    "y_0 =& \\sum_i w_{i,0} x_i + b_0 \\\\\n",
    "&\\vdots \\\\\n",
    "y_9 =& \\sum_i w_{i,9} x_i + b_9\n",
    "\\end{align*}\n",
    "\n",
    "We can express this in matrix form as:\n",
    "\n",
    "\\begin{align}\n",
    "y = W x + b \n",
    "\\end{align}\n",
    "\n",
    "To put this into our graph in TensorFlow, we need to define some Variables to hold the weights and biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define linear transformation\n",
    "# Usually DON'T initialize matrices and vectors with 0's, but the MNIST ex. is so simple\n",
    "W = tf.Variable(tf.zeros([784, 10])) #weight? matrix      \n",
    "b = tf.Variable(tf.zeros([10]))  #biased vector\n",
    "\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret these values (aka logits) $y$ as probabilities if we normalize them to be positive and add up to 1. In logistic regression, we do this with a softmax:\n",
    "\n",
    "\\begin{align}\n",
    "p(y_i) = \\text{softmax}(y_i) = \\frac{\\text{exp}(y_i)}{\\sum_j\\text{exp}(y_j)}\n",
    "\\end{align}\n",
    "\n",
    "Notice that because the range of the exponential function is always non-negative, and since we're normalizing by the sum, the softmax achieves the desired property of producing values between 0 and 1 that sum to 1. If we look at the case with only 2 classes, we see that the softmax is the multi-class extension of the binary sigmoid function: \n",
    "\n",
    "![sigmoid](Figures/Logistic-curve.png)\n",
    "\n",
    "Computing a softmax in TensorFlow is pretty easy, sort of*:\n",
    "\n",
    "*&#42;More on this later*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax to probabilities\n",
    "py = tf.nn.softmax(y)  # nn subpackage stands for neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That defines our forward pass of our model! We now have a graph that performs a forward pass: given an input image, the graph returns the probabilities the model thinks the input is each of the 10 classes. Are we done?\n",
    "\n",
    "Not quite. We don't know the values of $W$ and $b$ yet. We're going to learn those by defining a loss and using gradient descent to do backpropagation. Essentially, we'll be taking the derivative with respect to each of the elements in $W$ and $b$ and wiggling them in a direction that reduces our loss.\n",
    "\n",
    "The loss we commonly use in classification is cross-entropy. Cross-entropy is a concept from information theory:\n",
    "\n",
    "\\begin{align}\n",
    "H_{y'}(y)=-\\sum_i y'_i \\text{log}(y_i)\n",
    "\\end{align}\n",
    "\n",
    "Cross-entropy not only captures how *correct* (max probability corresponds to the right answer) the model's answers are, it also accounts for how *confident* (high confidence in correct answers) they are. This encourages the model to produce very high probabilities for correct answers while driving down the probabilities for the wrong answers, instead of merely be satisfied with it being the argmax. \n",
    "\n",
    "In supervised models, we need labels to learn, so we create a placeholder for the labels in our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y prime above is the actual answer (same as this label placeholder I think)\n",
    "# Define labels placeholder\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-entropy loss is pretty easy to implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss                      \n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(py), reduction_indices=[1])) \n",
    "# reduce_func collapses 1 dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the old days, we would have to go through and derive all the gradients ourselves, then code them into our program. Nowadays, we have libraries to compute all the gradients automatically. Not only that, but TensorFlow comes with a whole suite of optimizers implementing various optimization algorithms. I'm not going to go into the details of why you should appreciate that right now, because I know that Prof David Carlson has an entire day's worth of material on optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer          \n",
    "#not a great optimizer, but again, this ex is kinda trivial\n",
    "# training rate = step size = alpha = 0.05\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train, we simply call the optimizer op we defined above. First though, we need to start a session and initialize our variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session object and initialize all graph variables\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are much cleverer ways to design a training regimen that stop training once the model is converged and before it starts overfitting, but for this demo, we'll keep it simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 642.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# trange is a tqdm function. It's the same as range, but adds a pretty progress bar\n",
    "for _ in trange(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100) # returns a tuple\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys}) # why feed a dictionary??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, because of the way the dependency links are connected in our graph, running the optimizer requires an input to both the training image placeholder `x` and the training label placeholder `y_` (as it should). The values of all variables (`W` and `b`) are updated in place automatically by the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we did! For every image in our test set, we run the data through the model, and take the digit in which we have the highest confidence as our answer. We then compute an accuracy by seeing how many we got correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.9017999768257141\n"
     ]
    }
   ],
   "source": [
    "# Test trained model\n",
    "correct_prediction = tf.equal(tf.argmax(py,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "_acc = sess.run(accuracy, feed_dict={x : mnist.test.images, y_ : mnist.test.labels})\n",
    "\n",
    "\n",
    "# I trained it with 10,000 steps and now it stays at this accuracy\n",
    "print(\"Test accuracy {0}\".format(_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad for a simple model and a few lines of code.  Before we close the session, there's one more interesting thing we can do. Normally, it can be difficult to inspect exactly what the filters in a model are doing, but since this model is so simple, and the weights transform the data directly to their logits, we can actually visualize what the model's learning by simply plotting the weights. The results look pretty reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAACBCAYAAABXearSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnV2sXVd178dqICTgpImd2E7i+AsnIQmFBMLNpaGXtIiqQipVH25VHq7yUKlqxZWKRKXC5blqL6r6hlQhtaUPFVdXolIpqoQqVHQblKYJIcEOduw4jmPHJp/QfDRtCV33gXNWf/PvM4f33mefvdda+/+Tosx91tprzTXHHGPOtT0+mrZtwxhjjDHGGGOMMcaMm59adgeMMcYYY4wxxhhjzNbjH4GMMcYYY4wxxhhjVgD/CGSMMcYYY4wxxhizAvhHIGOMMcYYY4wxxpgVwD8CGWOMMcYYY4wxxqwA/hHIGGOMMcYYY4wxZgXwj0DGGGOMMcYYY4wxK8CmfgRqmuaXmqZ5ommaJ5um+cy8OmUWi+U4fCzDcWA5Dh/LcBxYjsPHMhwHluPwsQzHgeU4Lpq2bWf7YtNcEhHHI+KjEXE2Ih6KiE+0bfu9+XXPbDWW4/CxDMeB5Th8LMNxYDkOH8twHFiOw8cyHAeW4/h4yya++18i4sm2bZ+KiGia5v9ExK9ERHUyXHHFFe211167iVuaWXjhhRfi1VdfbSqHp5LjZZdd1m7btm1rOmpSXnrppRfbtt1IgabWxW3btrXbt2/fmo6aKi+//HK89tprc9FFy3B5nDlzZm66+I53vKO96qqrtqajpsoPf/jDeP311+eii5dffnl7xRVXbE1HTcoLL7wwV128+uqrt6ajpsoPfvCDuenitm3b2h07dmxNR03KM888MzddvPzyy9srr7xyazpqqrzyyivxxhtvzEUX3/72t1uGS+K5556r6WLBZn4EuiEizuDz2Yi4O/vCtddeG7//+7+/iVuaWfjc5z6XHZ5Kjtu2bYuPf/zjc+qZmYY///M/P105NLUubt++PX73d393Xl0zE/JHf/RH2eGp5Lh9+/b49Kc/PaeemWn41Kc+NTddvOqqq+K3fuu35tU1MyF/8id/kh2eSo5XXHFF/Nqv/dqcemam4Qtf+MLcdPHqq6+OT37yk/Pq2pbQNM2G7f/4j/9YRnfmwhe+8IXs8FRy3LFjR3z2s5+dU8/MNPz2b//23HTxyiuvjE984hPz6pqZkC9/+cvZ4ankeOWVV8Z99903p56Zafj85z9f08WCzeQE2uiXwgtiy5qm+c2maR5umubhV199dRO3M1vEReVIGf7rv/7rgrplpmBqXXzttdcW0C0zJVPpomXYS6bWxddff30B3TJTMpUuvvHGGwvqlpkC6+I48Lo4fKbWRdvUXuJ1cWRsxhPobETciM97IuKcntS27Rcj4osREQcPHpwtAdEMTJrriP+SEhHxUz/1n7+L8V9W9Hr8Hr+j5876rzPary3konKkDK+55pqFyXDeqJw4xj/+8Y8X3Z15MrUu7t27t3dyVB3j59q/furnSy65pDhGuU6qiwvUPWUqXeyjDM30unjDDTfMVY6qR9m851zP1q0333yza7/lLf+5bcj0TeG589CxLdbTqXRx586d1sX+MbUu7tmzZ65y1D1HpgPUOZ6nOvbWt761a//7v/971/7Rj35U7Ue2f83g97I99aTnzchUurhv377e6eKs7yMjYmpd3LVrV+/kOCmbyLU7557Mnal0cffu3b2XYe09Izsvs6cDkGHBZjyBHoqIm5qmOdA0zaUR8esR8dX5dMssEMtx+FiG48ByHD6W4TiwHIePZTgOLMfhYxmOA8txZMzsCdS27ZtN0/zPiPh6RFwSEX/Wtu3jc+uZWQiW4/CxDMeB5Th8LMNxYDkOH8twHFiOw8cyHAeW4/jYTDhYtG37txHxt3Pqi1kSluPwsQzHgeU4fCzDcWA5Dh/LcBxYjsPHMhwHluO42NSPQMtg0ljLSfN/ZNfjNZgTQY9luWZ4LMs/lMUR6vVr9xobWY6YDI7X2972tq6tY3XppZd2bcbW6+chV93oAzrumuOg9vdaPh/mRIgoc5SorPiZ19P8CbyGUss5pP3d4rwIS2XSfE2z5t2inCaNy85yQ2WM2WZuBMc9kwGT/ut5PMZ5Txsakc/7yy+/vGtznqg+Z+tdjVWTKamtT/r3Se1TlmOtltMms7uzMss8WBa1+afPQH3J5v1P//RPb/idiIh3vOMdXZvjrEU7dE9DamurzgteQ/fAXEN5nt53Uts+RCbNk5TpA+U+zb5hlrEc2/jPi2x/Q9llNjWTcWZ7aVOzveykOfWGnJ9mq8jGf975YGvvNxH9lM1wVlljjDHGGGOMMcYYMzP+EcgYY4wxxhhjjDFmBRhEOBjdt+i6lbnwqUtWrXxmFoJC1zx13eK91E2W7rBvvPFG9RqXXXbZhveKKF2F2db+ji1UrCbriHKc2Vb3Y7pPZ2VTGZ6gY/Uv//IvG14jG+/MdX7SsMCxwPnMeR4Rce2113ZtyoryiCjnPa/3z//8z8V5r732WtdWm/DDH/5ww7a6znOuZeFmPKbPlYWU9RWGS+rY8Xl0jlInOA67d+8uzrvqqqu6NnV2586dxXnUYcozopQV26+//npxHm3t+fPni2O896z2dChkbulqDzme//Zv/7bh3yMiXn311Q3PUx3g+OkxhrFQ16+44orivGzdrTGG8MtJwwmUmjv7pCXDdc5Tbtmxt7/97V1b+56FIFLXdZ4Ryr5v8p00HEPtSxY6y7HNQj+oi1w/s9Az3aNS/ybdBymcX7S9ar9/8IMfVPs4xFD7bI9KMh2YJQRs0nQS06SWqJ07xHeHjZg03YfKh8eyUMfaewj1ISLXe+op10K137QPurbW7IA+11jkuhEq61oYn44JP9feMfW8LLVIloKEstF5MGl6mHkz/B2vMcYYY4wxxhhjjLko/hHIGGOMMcYYY4wxZgXwj0DGGGOMMcYYY4wxK8DgklhkOYEYU6exxswDkZV3ZxxmVo6YsZsaA81jjO3WGM9JyydnOWkYl5+VpusTmZyymEx+zmJ9t23b1rWZo0TjaBm3qzG8tTjR7du3F+cxFlT7xHwHWcw8c2D0Pa8M5cW+aj4fylhzfjAfDONnOZeV559/vmtneRYUXp9ld7PYbuYwiCjlyj5eeeWVxXmcd33KLaN9odyYs4c5WyLK59N5TxnwPF4vom7XmNdC+6j9feWVV7o27bjq0blz57r2Sy+9VO0v7anmMKI+9z1+ftJ8Dtk6w7HgOGdlnmlHJ825pv1gW8/jPJw0f5r2l7lM+pZPhtRyT+jax/N03hPKRkuL13JW0C5GlDqc5SrkMeZbiyjztl1zzTXFMeoi76VziTm/dDyWLVO9P+dpVradz6Fzm+fSPup6xHHiWGblqzUHGz+zT1zDIkr5qO7RlrCPOheyPvbVxma5ingsywfKts5tfs5yB5Eslwz1knueiHL8Nd9hbd2dtMx1H6nlbMpyvOjY8vm552M+y4iI/fv3b/id6667rjiP9vbs2bPFMX6m3qscuS4+99xzxTHONcpY+1t7D97ocx/J8v5Mqoua54yfeR73QxEXviMSrqHcD6sMudfRtbW2dut589a//rypGGOMMcYYY4wxxpgtwz8CGWOMMcYYY4wxxqwAvYk9maWUn7pF0cUyc4mn65aeR9c/uvSpW1fmYk8XWro0nzlzpjiPLrTq8sUyvAxt0P7SBTEr19sn2C914eN4acgI5Us5qdt7zR07K4/54osvVvvB+aKypnufhgdRhi+//HLUyMqw9o2a+7C6GXPMduzYURzjnKXeq7slXTOpH+q2ypAeDWmiHNXVnXCuaVgawy+yMtpZqd1Fu1DzfiobzlPaOJUT5cvnjih1kfP35MmTxXm0XZmsGW6mevTUU0917SwklP1QfVM7s46GKnJu9j00k7CvKm/qi7r510KvNHyBdo/jrOF0XIN0bNmPq6++umurvlFWKgOurfzes88+W5yXhYMtM5xBbVetXLrqG2Wq40V9ycq7c0y4n1HdYFgl5RRR2risFLHOC0IZcu1We8rrZ3uBZaDPy3nKcc7CGXVu1/YBR48eLT5Txpw/GvrBMdIQQo7n9ddfX+0Tz9N5kqUpINmevU/QTqgNJbWQeL0G57PKlscoGz2PY6f34phn4SOcL7q20pZQt/V9J5PvsmWapZTgOKvNyJ6J6yLlc9NNNxXn3XDDDRtePwtN2rNnT3Hs0KFDXfuBBx7o2mp7ia4PtNk8pntefu7zewf1iGOpYd98Vh0Tyo3PTZlFlPOX8/7UqVPFeXxHPHbsWHGM4c/UNw11p77p+3otTFpTLPB7mZ2alH7+SmCMMcYYY4wxxhhj5op/BDLGGGOMMcYYY4xZAQbh715zZ8+qIajbGD9n7lQ118bMDU1DUHgNunKpSzNdz9Tli66FdAfWzPK1iit6/T5BF011Ac+qaNF9kW6yOnYMs9PKGoQufOpKyLlVq+ASUc6frBIInyu7V9/QOVWrCKZuxjymoT+1SjesABZRuutSZ7PwjiwEgv3I3LP1mXk/6rC6emau28tE7QBllVVkYwUKDSNiqA/Hh+F3+r0bb7yxa2vlhSxkiZVs2PfHHnusOG/Xrl1dW2Vz4sSJrp2F3VBnp6lCtwh03tdCgVUH+L1MdzhPdK3i3OaxF154oTivFqIQUYb8nT59umvv3bu32ietalSrZpf1Q1lmZSkNE+D8y+wHn1Xndq26pN6rZrt1/8I1M5sHtB0a+scxztY7ylNDFzhHsvDEPlDTMV37+Iw6tvzMMFqdy/xMW6YVgygTtctcd59++umurXsp2oTMdtAWZfYnq8K0CNhn1THOS+7rsrANXVsnDZFjaAn39DrPs2pCfBbKV3WDz6K2o7ZHVWjL+7Au1sKF9DPHQvfuHAsNveJY8166bzl//nzXZroPXfvuueeeDc+LKEOZv//973ftffv2FefVQo4iyhAzhneqjak917LRdyDqAasN6vjTjunz0JZxvLQaJu3kO9/5zq5NmUWUOqs6QP2jHjGVQUS5tmoKEtp8vp/o2LDa5jzsqT2BjDHGGGOMMcYYY1YA/whkjDHGGGOMMcYYswL4RyBjjDHGGGOMMcaYFWBpiSumiUesxX/rNRhHqDHQLJ+ZxcjympqThjAOtlZ+WPukcaKMdWS8Z0QZp8iSdvyOXl/Ho08l4mv5mjQOmfkDNJ61FmuvMZPMG1KLD44o4zNVNowhZT80f0KtfLjejzGeOjd5TY31XQZZnqlaXzUnEOezzkPGPfM8zU/DMeO9NPcSdUJ1kfHW1KmsBKrKmN9jHG+W62jRZHmMFOZZYXyx5pTInrVW2lllzXvxelrOmP09fvx4cYx5NChPLbVKW6hzhDKlPqvd1XjxPqEyrpWzz8pnq42qlSrW8eO4816ac433zsonU581Np7fUz1lToBJ884sm1p+uYgLcxysozaIn3WOcsxpQ9UGcK7Ttuq9eL0dO3YUx2rrU5afUddWXp/Xoy2KKNdPtU19g33NcgjyWJYfiufpmPN7PE9tL3X45ZdfLo5RPlmpaK59Kkdeg+ddd911xXm13H7LIMtZVhtzzZNE+6Q5OPg92i6VNa9JfVZbSH1W/eC6SFnoOwKfS4/V9qi6hmS58vpGTcZq57gH0f0r5cB8QY8//nhx3smTJ7s2ZaB5fyhHtfksN37zzTd37e985zvFecypx7w/EaUc3/ve93Zt3d/oNcmicztxvHS+sd98X9B9KOesln7fvXt316au6Ds/x/zgwYNdW3MyUbdVho8++mjXZi479iGi1PvsfSfLjZvZZOcEMsYYY4wxxhhjjDEb4h+BjDHGGGOMMcYYY1aA/tQxBupanIX0EB7TcqPq7reOupHT1YouWXTFiyjdpFn6OKJe6lNdg+meqP2gyxrdRekaF1G6Sfcp/Euh6x/dDrOwFXVPrJXxZnhfROmuS/c7dZWj65+WJ6frLUMeslAklS9lyu9loWdZGdY+wLFl37IwxUxnb7/99q6tbo8s+8xjqsuUq4an0OWX+qzhSNTZzE2f4U0arlgLc4jYejnqvMnK8tJNnW6t6jrM587CNjn+6ibLsaRNVnvKeaVu29QXuu5qf2kz1YWfn7/yla9s+J2I/pWeJln4cxYKzWfKwo45R1UGnPfsh4YvcO3WsaXe7tq1q2tr2BjRdZGu1rx+Nu903LL7bTW6t+G6QD3SeUiZajl2npuF43FM2NbQBY6luulzXrC/2if9XIPr7IEDB4pjWSj9sssbZ/enTHX8shQDlGN2/dp53GtGlOEFWWll7iFV7xnOoGGItVAiXeto63UPtlWhRevjojrAvaI+K8/lfNNrcB3TUDq1r+voesexpG5zfdN7aWhsraS97l84B3XPUgtZ0+fiHkJt2CL2qNPsbyg7rjkaQsVwHJZ6jyjfDbgP1VDH97znPV2b+vA3f/M3xXkPPvhg1373u99dHKMNZJ9uu+224rwsdQLXZ333JVmodRZGPg+y93q1i5yn/J7qEZ9Bx4s2j/vXJ598sjiPIX4f/OAHu/Ydd9xRnMc+Mjw+oiwFzzHW/RHHmDLTcznn1EbOe+3r768GxhhjjDHGGGOMMWZu+EcgY4wxxhhjjDHGmBXAPwIZY4wxxhhjjDHGrAC9zAk0KRr7ythUjRPlucwloKUzCfMWaCwt4/c0bwFj/RiTqnHtvIbGEjOGkf3QOELmsll2nHwG4zp1vAjHKIttZTw3SzhGlPHRzP2yf//+4jzG92rpR8bJM9ZXc84wdlpzAnHOZc/Vt5KbnEcaD8+x4NxWPWI8ro4L5zDnQlaqtlYOO6KMqdZcMMyhRZuguZ0oKz2WlfcktD/LzuXE8dL5RRnSBmleJ8pD7RPPffrpp7v20aNHi/Moj7vvvrtra+6Dd77znV1bc8kwPprjrzkdmJtNY7H5LCwtr3JaZr6YiMlzjUTUS1FrfD2fSceWx5jHSs+jHeWao7nUaFM/8IEPFMdop3l9tQ/ZGND+0kar/eHcUJuwTPTZdE+wjo4/c+xoPohabh597lr+D13TOJaaZ4a5THj9bO3T0r28BtdCzbfBe6ueLtu+qhypi8z7oP1Um0Vq+aE052Et357Km3LUnCfUHZLln9A9NdduzmPNLcKcN4sqEb8+7jr+fD7VsVqOzmn2/rwfx0HPow5QL7WkNPuo84Cy5xqpuZvYX9UxruN858jGTefIInKRan+ob5prhuPJNUdzSfJ7Oi619zbuNSNKHeNayBwxERFHjhzp2pqDjXmFaEe1v/ys+xR+phyPHz9enMe5rOvI+ve26j1Sr8v5qznwaAs55voOx/HSHEe1tVB1kWsVdeWJJ5648CHWOHz4cPGZc4lyUl2hnJ555pniGPWIuq76Ne+176La2zTNnzVN83zTNEfwt+1N0/xd0zQn1v5/dXYNs3wsx1Gw3zIcPtbFUWBdHAHWxVFgXRwB1sVRYF0cAdbF1WGSn3C/FBG/JH/7TER8o23bmyLiG2ufTb/5UliOQ+fFsAzHwJfCchw61sVx8KWwHIeOdXEcfCksx6FjXRwHXwrLcSW4qO9727b/r2ma/fLnX4mIe9fafxER34yI39tMRyYtQUj3KnUv4zXUXY7n0jVWQ3N4b7pKqvssr3H27Nni2Pvf//6uTTc0ddOny5e6cNbcGDX0ic+cufEtSo6T9IV9VjdAfk/ddXmMY6JujfxMV/QsPOHcuXPFMYYRUW4agki3RXXbYz/oBq1ui+rmm/BaRGj84pbJMOLCZ2LoAOWh40KdUPdFHqOrrYYUMPSHMmD5zohS1zVckvrNfmTzTp+Z/aL9UdvBZ8lcNhehi3wenV+nTp3q2pRFZuNOnDhRHKNLM8M2tDw5Q69+9Vd/tWtrWADvrbaD+pKVkucxDWPh9dXW1q5xERaii1yPshAU6ofqEcdv0hLQei+WZv3a177WtTUM6+d//ue79t69e4tj1BeGL6g9pO1Vd2o+G2Wq82nSsJNFr4tqFzjmtDsa2kOXeJ2/HD+GoKgMGdLHfmhIGtctDRHlZ+p6LbQg4sK1gf3nc2lIBm30RcrkLkQXeU8dWz5jVoaZ+xadC7UQiCwMlGG1p0+fLs6jrHRNo95T/ipHpiJgeEVE+ZycW1m4hbI+jm3bLkQX2edJ3x84lyNKG6Rhx5zbnLO6v+S6e+jQoQ37EBGxY8eOrq02gfKm3PT9iTLUY3w2ym2a8Mtl6CLR+cVxohx1bed81hBGvhtQV3S9Y5g87aGWgacuHjt2rDjG/dlNN9204d8jyr232mzOG8qR62xEGQ6mc239fk3TLEQXORd1fnGvwBAwDQfjO4Lu/Skb6qXugbiPeOCBB7q2jh3tsNpC7o/4LCpD6qnOR6YsoHz1d4N5h1/OerVdbduej4hY+//Oi5xv+onlOHwsw3FgOQ4fy3AcWI7DxzIcB5bj8LEMx4HlOEK2PKNX0zS/2TTNw03TPKwJ1swwoAz1X6XMcKAc9ddlMwwsw3FAOar3lBkGlKF6C5jhYF0cPl4Xx4Ft6vCxDIfFrKVQnmua5rq2bc83TXNdRDxfO7Ft2y9GxBcjIg4ePNj5DWbZ3tVNszaRNHs6XcDVvY/hAXTD0h816JLF73zrW98qzvve977XtdWFlj92sWINQyMiSpcvdfXUUKjaeXRLm6GyzURypAyvueaamVLH04WNz62uwyo3wjnDOaHzg+6vdMem263eK6towTHWMCK6jaqLJucjj+l5m6xINJMu7t27dyI56thyg0UXZw2JfPbZZ7t2FkLHsCIdW7pzUj633HJLcR517NZbby2O8XvXX3991963b19xHuWtLvx85lpIYkRpB9SGTVBxYWpdzGTI+2l4EMeVFRBOnjxZnMdKX1q5jfaJ8lAbx2N0kdbr0T6w2lhEKTfOJf1HBcrpwQcfLI7RbZjXyCr1ZS7wFWbSxRtuuKEqR8pO+8O5zX7TNTmitF+0jRGlCzVlqvawJh8NTXrf+97XtX/u536uOMaQQoYa6vykHdDwhVpFIg3/osv3ItbFnTt3djLUPhN15eaY0+6oazu/py+51APeW8eE84LV+FQXs1A9ypty0ipxtCu6l6HcaHM0TIIhRjP8A+JMurhnz56qLmb2gPrHPZqGsTG8R8edYc60UXoeZUd5a0Uirt0HDhwojlEG1JWsKiDtcET5nAxfe/LJJ4vzOJ8y3agwtS7u27evk6HqG3VCQzVoJxi+o/sXjl2mH9k+lyGv3Efp3pDrU1Zdid/T0DPOQd1j8dmytS9LOzHBOjmTLu7atWsiXVT7zv0l56yu9QwtUptKPWAVJw0z5zU//vGPd+377ruvOO8P/uAPuvbDDz9cHGP/H3nkka6dVVXUvSfPpaxYeSyiHDed1xP8YDO1Lu7evbu6LvL+qqcMJX/Xu97VtXW/wT23vt/RDtFW6b1oN7MwadpnXZ/5DsKwPX1mvneonvLzY489tmGfIko9nUdo2KxX+GpErM/y+yLirzfdE7MMLMfhYxmOA8tx+FiG48ByHD6W4TiwHIePZTgOLMcRMkmJ+C9HxAMRcUvTNGebpvmNiPjDiPho0zQnIuKja59Nj7EcR8GBsAwHj3VxFFgXR4B1cRRYF0eAdXEUWBdHgHVxdZikOtgnKoc+Mue+mC3EchwFp9q2vWuDv1uGA8K6OAqsiyPAujgKrIsjwLo4CqyLI8C6uDpsKhnJZpggR8aGMAZTS4oyxlBLmzKGknG8GhfMOMDvfve7Xfvw4cPFeYw31BwMjO1jrLSWFyQsQxhRxj4yPlVLxDPfwwzx1ltGVmKSMY0ag8742CxvFMv6Md9HRCkPXk/ny3e+853qNThfGCublYHPnoVtzROwyTwkW4rm62DuHOrHP/3TPxXnMXZa8+/U8n+pLlKO1HsdZ8pH42ypzxoTTiifrIwq4311PnHOaA6ARSdU5zOo3WF+DbZVB2gnNRb7Ax/4QNf+mZ/5ma6tdpex0pzbLG0cUdpXXRsYk8+cDsePHy/OY16qRx99tDjGuVQrjxwx//Kb05KtixrDz7w91AnNJcDnZU6SiHJuM3+CrkecJ5S96hRj+VVPKX/qiuZ0YB/1GPNZ0cbovWiX+2RT9Xn4mc+gawRlrbakloNQy9jymtR1zXNB28XcbhGlfrC/Ov7MY6P54niM6/ipU6eK8zjPdNxm3T/OC51TzLXCdUx1kfl3VMa0t1xnbr/99mo/mFtGYQ42zaNXm0+6bnEO6bOwnDVzjelzUd5qX9fHcVE6ynmTzSn2U/PoML+I6hjnM22Vlptmzjqe9+EPf7g475d/+Ze7tuY8oax4Da6XEeWame1LOG9VHtmxZegi+6C5zzjf+Hxqy3ie7htpz1g2XOc25XXHHXd07W9/+9vFedQd3XNQF5mbSNdg5gLTPXUtd6DqGz/rOrLV74813Y/I8+9wX6JzjzLUXJLMZ8bzNGcZ8/syp+Hdd99dnEf7rLnAOAcpNy1Hz/nD/kWU71b83YBrQUR/SsQbY4wxxhhjjDHGmAHhH4GMMcYYY4wxxhhjVoClhYNN41JIVyu6eatrO1201EWQLp1ZKVy6XtGlT0ugZuX06NbFtrrf0TVTwy14LCv3TDc6PdZXMndFHlMXc7q908VcyzvSNZZhBxoWQzd4nX+cF3S51nnLOZeVBVeXYrLJ8ptbirqIcmxZ5llL+NJlWsOm6OpIN3ItQcv5zO+ovBkWpCEzLOXIsdRyurVwxYhSJtRTtT8MOdLQqnX5L0qevI/OKbrGZm7VDPVR92PKl6Xk9fkYykAXXw3luv/++7u2hh2oHViHrvcREQ899FDX1tBCPjPndLYOLUP3Mjd8lSNtG8vdatgA5ZqVTGZ4hIY5sOQ3bR5DASPKOaN6Sv3mfXVd5L31GtRN6rqufTwvs8tbwTTu2pQv2+oCTrdytXE8pjpM+Ny8vu6BXnzxxa6t5clpr2kD9L4MS6PtjihlWgtHiSj3WHr9ZYe+Z6HqlIe6/HPcdZ7wGrpmEs517k10nBkCpuELtL+8L+UWUcpE96i8H9dZTVlAVG7r6+JW6aTuuzhxiwX6AAAgAElEQVSfdb5xr845qn2jDPmdiDIcmnulf/zHfyzO+4d/+IeuzTFhiF1EGSKpz0Ld4TV0XmWl6kkWLk9UhssOzdT7cy965MiRrq12k5/V3nIvxzCyn/3Zny3Oo75wP8L9TETEXXf9Z5ok7pciytBA7n10bvEdlPMnorQ51HW137SpOp+2er+j85L6p6GZtb2C7vn4DDovjx07tuF5uvfn9bNQdF5/z549xbFaWgV9ZuqfzjmGqdE+qwy5H9Zn1neXSbAnkDHGGGOMMcYYY8wK4B+BjDHGGGOMMcYYY1aAXlYHUzc1ulTRTVZdXOnKlbmA051WXUKZYZwuXuqSRRdLvZe60q+jbtd0FdYs4nQlzdy/lu2KOQu16lB6LKvSRFdYdWOkKydDJtT9ju6WGt7HymF0j6cLfEQ9nEL7xTmchQssIwQlC0HTvnKe0h38Ix8pK0fSTVbdwzmGvAZDPSNKd12Gu2j1C84F7S/duqmXKm8e01Auulhm/aWeqivvuu5vlb5m80aP8Vlpx/Q8ylrnNu0h7aSGbdBGZxXAOCeobxGlPtOGqp297bbbujbDEyJKV2rKTd1nufbosUXopt6jVo0pogzNob5ppQ0+r4YDcDw57jp/z5w507Vpl7VP1DdWM4koww3o+qxzi/3QMFP2l2OlawXX+Kwa46JR+8T5xlCSLIRTwzZq1TC1KhfvTTmprKnDGmJUu56G9NX6FFHKivfWeZvtBZZdxU/1tBZmkYXo6/PS3tK2aZWgxx9/vGtzXmTVKnXOc43L7Br1O6tOyLA01VnKX6+x3q+tsq06b9hn7rEjSp1jW0NSeQ3dUzLFAI9pGAvlQdutIXeUk1awYog2r6HvNPyers/sB3VRKwbymfuQsoD31DlV29drdTCuQfoMlAOrRN16663FedzfcCy5F4koq8NpKDxDwLgGMN1CRMTXvva1rq3PzHlOveceIaK0EVkF561Ar0+7oPOyFlapdqwWwhlR6g7nQVaNlPOeVeEiyoq2Gg5GO8z3E7UPXLu1siOrlHHtpjwjyrVPn2UW7AlkjDHGGGOMMcYYswL4RyBjjDHGGGOMMcaYFcA/AhljjDHGGGOMMcasAEvLCZShMae1PCSa36BWBj6ijL9mHOdjjz1WnMeycidOnOjaGj/MmG2ND+T12XeN1WV8psZ48lkY96j90O8NAT6b5hJg7LE+G+PrmXNAx58x9LXy0hGlfDU+k6U5Ga+qfWL/szK2nNPzKOu3lbCvmvemFoeuOa2om1ksMMdTZUAZEx0vxlTrvWqxxZpXg/HXOmc4X2lHtJwu9V5jgbc690GWI0PHizHQWe4U5oHRHAGMv6actJQ8r8/7qg5w7DTnE+cSx/8973lPcd69997btTUvRc2Gahw5+6tjuozcB5SJyodjyGfSnHq1MuQR5XhSBzTWnPJnPzT3Em2v5gJjjD7lo7nyKH9dH3hvzgvN40XZaUz9MvPo6bzPyhQTylTHnLrDeV7LvxIR8fLLL3dt6rmiaxrnTy2XRUQpG7W1fBbuo6ZZF5ddIl7Htlb2Xs+jTqie1vRK19ZajkydF7Rlp0+fLo5p7pl1VFe0xD154oknujb3CToXSC2n5VbppF6XtibTReqR2n3KWtdFfo/30nE9ePBg1z506FDXVn2j7HW+MOcaz9N3BK67urdhrhTKLSun3of96qQ5ZbmnZF6eiNJu6jy/5ZZbNrzet771reI8fo990rWP75k6tnznpO1Qu8z1WddxrrvMT6Nzge/PWQ7TRUA7pvLUHFrr6Du/jgPhekr7pLkkeW/KQvclLFuv+0vaEt5X5xznI98xI8rcXZxzmVx0LmXjUcOeQMYYY4wxxhhjjDErgH8EMsYYY4wxxhhjjFkBlhYOpi5OmXsfXZzo9qiujXRnVBdkup7RdUtLRdMFj9dT91mGPbB0XERZzppuoFoSlP1XF0u6BdI1TsscZuEcyy6jSihfutmpGz+fR91fKVO6P6oLHK/Ja6is6SKtrnl0o+T1dUwz11g+M932spK5fQhBITrv6VrMZ1eXdeqRunbSVZbX0FAihhtQBho2xjHSa9BdnrqjYSZ0pacrcEQpR+ozxyKiHCst57rVclT7SVuj7q98Bs43dR3m82ioCm0Xj+k16C5P/T1y5EhxHstjqp6+//3v79p33nln19ZwQbroqns37QVDYTT0jHNrHuU3NwvlquPC0AO2taw35a/2irJj6WktbU3ZUcc0JO9d73pX16ZbekTpGk17SHlElPNO7SF1OCv7SvRZZnGZ3gyZfef6xGPqis7nVvvHEJKrrrqqa+tz1nRWw2I4X7S/tB20oWr/KQ99FrVHG11Pv9eHstRE5xQ/M2RBx5ZzW0MbqGO0X7qXffHFFzfsk+4vs7AQjjXLWeuaRt3UvRrhHFQ58jl1Pi06rI/3y1IpcO6pzaQ8dC7z+bge6bvKTTfd1LWz0L/s/YH7Ktp/DSmjndRn5jUoa9U3fu5DOBjRvlIXORdpGyPK97Q77rijOEa5cow0PQKv8fDDD2/Yjijnk4ZtMrzw8OHDXfv5558vzuO4q/2pXV/tJOeJ2pVFy5V903lJ28X5q3sF7gEZrqXQ7uq6yPd87ld37dpVnEcbqrJhf2knNaSP8/HkyZPFMeotbWb228g8ZNafXwmMMcYYY4wxxhhjzJbhH4GMMcYYY4wxxhhjVgD/CGSMMcYYY4wxxhizAiw/6cEGaJwwPzNWjiX+FI0dZJ4Ext1qLCJjPhmPq306cOBA17799tuLY4xNZAygxkNn5VwZU8+YRS1pnMXG9yknEMePz6DlRDkOGttci//UeHceY86Fp556qjiPMdtZXgq2NQacsd4aa8rPlJPGeLKPy8hDonOIn1XHmFuFMeoqR+rRnj17imPUP8pU460Zs8zrazw0dVv1gzG+nE8qK467yoD95TNrThrG5+qcXJfxokrhUvc1Pw7tWpb3jNfU53nwwQe7NnWHpVAjytwHvL5ej3mifuEXfqE4xrwz/J7G+PNZmE9Kz2WMueZYy+zPstEcO6SWbyeinM8qY+YXYV4BzVfCuc6cWcwBpH3UuHnGx1OHVQa0OTqvef1s7eN6o3HzyywRr33ms3JPoXLiGqHjyj0G89xlOWKIljOmvVMd4/rH8/TaWU4g9pc2Xvcr1Gcdtz7tbSJKfeGao/nwOJ5qXzhnuRbqekdd5L3UplK3Nb8idZjrs9oO6kqWr5B7Wc0dxPN03V20HPk8WT4i9ln3hpzr2bsKn03zhnKPyrVKcwdR9pqXj+PMcdXccbR/eoy6ybbu+6jPKrNl2tOIC+csn4P91hw4zIWleSApE+517r777uI86iltgM4Z5nG79dZbi2OUI8f9nnvuKc6jvdX9Np+Te3QdG9pefZdZdJ41zhu1cXw+zTFGOO9pgyJKO0m9yvId0hZqfi7OCeawjChlzzyTei/KQ6+v/V9H5UJZz0Nm/VpJjTHGGGOMMcYYY8yW4B+BjDHGGGOMMcYYY1aAXoaDqQsV3cHoZqeuk5k7I92m6M6o16B7Gd3q1JWQ7p3qTk2XS7rhqrsXXd7U7ZrPTPdTddOvPVfE4stvZtRCDdStkXJjee+IMqyFoVyZrFmGT93S6UqtrnkMMaLs9V6cP+qaR9c/ykbDE2phY8uCc1Z1kc9Ld1KVI0tnapnEWglddXfmOGXl6BkeoeWxWc46C7/kc6oe0f2SbsOqs0ePHu3aWTndrSALB1M94ljSjulzP/LII12btjCidGfnvTXsgGXHqb8arvWxj32sa997773FMcqGYTI6NzPbQRiioSEUGobTJ1Q+tGe1EtUR5VqiIZdcqxguqzpG+VOPOOcjyrVKbQLL5vJZNJSIfdT5xGsyrFFDa3j9PoUOqZ7ShtKeHDx4sDiP40B384hyHaM8dS1hyVvKV/c2vJeGlHGt4n31GrSZWcg9r6dy6lsp6gz2neuRhgzTbmbjwrA+DdtgmAhttJYcpkw0jIXXpKxOnToVNXSvTL2ljVH7k4VhL5psv8xnoB6pHaOtVftU051MP6iLumenjmmIkermOjrGXCc0XL5mG3XO8XOf7GnEheFCfDfgnuPGG28szuP4ZWFyd955Z9fWZ//2t7/dtRk2duzYseI87ksfeOCB4hjtwIc+9KGure8a1KOnn366OEbbzu9xLCLKubEI+9o0TadzuvZRF3UvR3lwL63rPG2eHqul8dD9xvHjx7s2x+7d7353cd65c+e69uHDh6MGdVjfETgG2g/OgywlB485HMwYY4wxxhhjjDHGTIR/BDLGGGOMMcYYY4xZAXoZDqYud3SToiu6uqfye+pWSfcyhm+pyxe/x5AFdd3VEDBCly9+L8tKrq557G8ta7jeq09ovziudN/csWNHcR7d5+juH1G6b9LlWN1fWSmHrrbnz58vzuP433XXXcWx2vVVTplrcM31WPvLa/YphC/iQpdFukbT1VT7zWdSl3ieS1dH1WfKIAs54pxR+dSqsqn7L+eJul+y/5T3k08+WZzHaixaYSyrcLAV8Lk1tIfPRzdZdRWnbdSwKVZRoGuyVsOh7aJLtFaVoiuvur0zhIJzQl2dqWMaksBQJ8opqxLXh9BMzlmdl3RZZ181fIGVSXQt4RhyjqrOMgRp7969XfvQoUPFeVzvNCSSMuF5KiseU/nwGMdG9S2rHLpM1E7WqhKqnGgbdc/C9Y56qmNSCx/RfUltrdbrU2fVJmdrJvtVW9M3+l6f4XzjmKku0j5qyA3HjGOkobOcG7yvhhBy/FSPuK5nYfGUT1aFKduj8jyV6VaHFqkNz6qD8Rj7rHtZyld1jM+T2SDqTq1aXkQpJ+q5Qv3TfTPXU9VnhsxwH6V9z96tlrFOUiZqNwhDwDQcjDqhaxVTE3AufP3rXy/O4zrJilG6v+S99J2H8mIYu16Dc0b1hvsxrumql4sOx2zbdqJ31KzyYM22RpQ2Sd9VuJ/lc+s1qMMMH3zooYeK87hOqt7zWPYuoeskqYW3a0gZbWgWYjcp9gQyxhhjjDHGGGOMWQEu+iNQ0zQ3Nk3z903THG2a5vGmaX5n7e/bm6b5u6ZpTqz9v+4aY5bKm2++GZbhKHir5ThsrIujwbo4cH784x9bF8eBdXHgWBdHg3Vx4FgXV4tJPIHejIhPt217a0T814j4ZNM0t0XEZyLiG23b3hQR31j7bPqLZTgOLMcBs+auaRmOA8tx+FiG48ByHD6W4TiwHIePZbgiXDQnUNu25yPi/Fr71aZpjkbEDRHxKxFx79ppfxER34yI35v0xlmsblYqlMc0lj2Lt2NsHq+n8dbsF+PyNB6X52luCsYmMi4xiyPUuFbGcjI2NItBVtb7+Ja3vCXatn0kYr4yzMhKVmd5f7JYSI45v6cxyhx/5gLJSn/v3LmzOMZyrXwWjR3O4m9rpfyy3EEX4UeLkCP1Q+cb+17LeRRRxrarnvIzxy8r/c48Lhorzf5qvC8/s4ymlpKn/mmZcD4nr6f3Yu4VPbY+hy655JKF6CLlpLaFuSgY+87cOxFlPgjVZ16fJU81BvrMmTNdm7lkGMMeUeoVZa1QL/W5KFMt0XrixIkN77WJnEAL0cVJbQNtnsbGMw+J5lui3lLeKkeOC2Wqek+7rGNLe06917mVlZRmLj6ep/luJhm3Reki0fGirDh2KifuP1RPOSZcC9Wect7TBmu+r1rOsIj6XkzzxXAt1GtQT2l/1GZS9tneLhaki2TSfEu6b+Szq/2iHPm8Wrade5Wbb765a+teinm8NB8i5cO1Wucd55Pme+O5fH7N+8P5pOO21XtUtS1ZbkHKg8+d7df0eWr5DrP9MK+veflqeREjSttBHdZr0NZqGW32lzLU5yJ9WBeJ7v/5HLQp3DtERNx2221d+5FHHimO3X///V2b65aWZqeN3b9/f9fWfJHMHfTYY48Vx6gv1FOVFW2H7l+bSk5A3XvrNTeiD+tibQ+g71gcL9UP2iuOia4ztH+Uk9o7zp9Mj6iLugbX9E2vyTVT30eom/PIITtVTqCmafZHxJ0R8WBE7Fr7gWj9h6Kdle/8ZtM0DzdN87D+WGIWz2ZluOgEt2ZjNitH3SiYxWMZjoPNyjFLqmoWw2ZlqD9Mm+VgXRw+XhfHgW3q8LEMx8/EPwI1TbMtIr4SEZ9q2/aVi52/Ttu2X2zb9q62be/SfxEyi2UeMpzkl2SztcxDjlqFwiwWy3AczEOO+q9FZrHMQ4Za2dAsHuvi8PG6OA5sU4ePZbgaTFQivmmat8ZPJsNftm37V2t/fq5pmuvatj3fNM11EfF8/QoXom5M/KzupHSJ5K/86pZIlzL9Fx2W+ePE1FK4dJ/j9fTHj6xEOV2cs7LUk7p1ZSEKWUgO770VMlTkfsUxLsx0m1RZU04akkBPMj4rQz30PKIhKNzwqYdTFpJAshKqnIO8Rs11fBIWIcdaGFtEGarD59C5R5nouNC9kbJS13m6VWYlSnkNLb/Jkpt0t9fFiSEuWfgU5zhL60aU7tlZ+MIiZEgYphZRL+Otusjn0TE5fvx4167Z1ojS5Zo2gDYyonRvVjt5+vTprr1v376urS9sJ0+e3LB/EeVz8lm0v1OEZi5cjto36h9dlTVklcfUtZjzmTZKw2Opc1yDVRdpNzUsrVZSXO/F59Tr18po69ydVI7LliGfgXqqoQv8rJ4OtdAVDQXgvaiz+o9z2b6EdpjzTO0/9VnDlHhv2qLsXhcJB1u4HHVPQPmwreFVZ8+e7drcB0WU4c/UbU1ZQLinycona6gE5UM5qs5yjdN9FfU5CyHnsUwvFyFDziMdk1qYl/6oxH2pzgPKgOOj7w8cZ35H90rUAQ0BYrgKdYz6pffW9Y7HpgiFTlm0Lup7Qq2keLa/0fdF7iOfffbZrn3gwIHiPH6PYbqq27QD2l/Ki/1Vm0r7yPCmiFJetCM6nyjji6QSWeh7hspGP6+jepT94Mu9DuWk+3bqjto/wvVUx5XXpF3RMFzq8O7du4tjHA/ubfWZ2Y/Mhk3KJNXBmoj404g42rbtH+PQVyPivrX2fRHx11Pf3SyEtYliGY4Dy3HAWBdHheU4YKyLo8JyHDDWxVFhOQ4Y6+JqMYkn0D0R8T8i4nDTNI+u/e1/RcQfRsT/bZrmNyLimYj471vTRbNZ1v7l2zIcPtvCchw0a7/iW4bDx7o4cKyLo8G6OHCsi6PBujhw1jyTLMMVYZLqYPdHRM3H6CPz7Y7ZCi677LJo29YyHD6vWY7D5m1ve5t1cRxYFweOdXE0WBcHjnVxNFgXB86ll15qXVwhJsoJtBVk+Xw0VpEx8IytzPLOZCX0mI9C49AZM3z77bd3bcaFRpTx0RqfybhL9lfj2vk9zQFQK7Wbxc1rfOCi4RhrXxgHyzh2HRPKRuN0eU3G1rMUakQ55pwTmg+DcZca281jjP/UWFDG8Go8KWUzaVx839DnpS7y+TQ2l8dYYlOvyXaW74q5iDQnRhYjy2NZSWnmXchyO3FuaWllzoWsrOwi4DhoP2t6qn1kroinnnqqOEZ7RVvFHEwRZUw0bZfaMeYB0jwavD7zRmmsNOdIVvaa9ln1vs+6qX2rrQuaF4vjlK0RHGfVD85tXl/X6lpOPe0H76Wx8Vl1H+bB4JzRe/Gzjtsy18ns3lw/NG8Bc3noOsa1hbZK78UxZ360zI5luUxoA3S+0P5pTjKS5ULMbNOy9zqas4LrH59d15LMRnGPyTxomsdl7969XZvzXPehtHmaZ422nf3QdYtyVVvJZ8v0Lcs9sky0nxwv7v80byjloXu+Wo49zadUywmk7y28l+6Hua/iMc0JxBx4qs98zloelr6jz0QZUKeOHDlSnJfZHuaIpL1973vfW5zHfGrsh+o99Vn3w9Qr6p/aB659Oif5nJzXui/nvfq019G5xz1a7Z0jotRZHRPKg+epfvAY9576Ts51TPPt1XKWqk2+8cYbq/3l/TgearvnLbd+WmdjjDHGGGOMMcYYM1f8I5AxxhhjjDHGGGPMCrC0cLAMLTFJd62shBtdhNXVj65XdO9Td7laeVp13aJLmbprsY90IcvK6arrWa3sa59c+DKysBy6yGXl79SVjuPMMaZre0QZkkJXW5UT+6j95bksuajzLwsBouvlpC7RWVnIRcF7qgsy3ZrVrZLQnVFLedPFnNdXXeQxusaqqy1lpzLmePJ6Ou/4PdUxHqOrsT7/MmRVg3NRSwdzvKg7mau4urNzbvN6eg26MF977bVdW0tnUq+obxFlmXmuDY8//nhxHmWjMqSsam7CG32vT2Rl0Dn3tOS3yoRQjtRLHQdenzLQMCBeT/WZ39u1a1fXVpvH/mehYVn4Qp9CULJQmVq4qtoW6nDm4s+1T13WaTepf7rfou1Qm1YLf1Ybzz6p/aHc2NY1mPdedviXkoUSca+o9oVhfrRXERGnTp3q2gxdUfkwHJNzQe9FdD7V1ufsGjoXeC6vp7rXJ5uapU/gONTCnSPKEK3jx48Xx2rroo4ddZHhQXov2gQdR9peykLnVWavaza/b/qmsK+qH+TkyZNdW2X1xBNPdO1f/MVfLI5Rx7hv1P0wS8YzfYjubxjyrOvW4cOHuzZtr75PZKXHOa85d9X2ZjJepp6qDGvrovaRx3bu3Fkc456VNln1g1CPsvVIbRznC59Fwzuvv/76Ddt6Tb7vZPv3edCfnZIxxhhjjDHGGGOM2TL8I5AxxhhjjDHGGGPMCtDLcDB1taKbJt1a1cWVGdgzl9SaC3xE6VJGtysNh2CVBz1GV7bMFZOuZ1l/2e6Tm3uGuu2xQgEz72cViTQcjO7nHHN1e+c1s8oIdO3UcaVbPb+n52WVhmrug5nbZZ9CiiIudEnlWGcV8niejgvdYSkfDWOhC2dW5Y1yzFzWGWakrsGUo4Y21Kqg6HzKKhwu2r2afVYXZlbgY78OHjxYnMfwLR1zfo8ur6qLt956a9em/VOXXLo3q7s0KzZ885vf7Noqa7rpa0UdXpOyHkolm4i8rxzbzB7qPNQ1aaNr6zWz6lFck9V2UNcZYqnhTZy72bPUQi/0vD6HNnAs2U8df85nDYet7Y+ySioMA82qCWmFGt6LsleXdX5WPeWcmzRkps96GVEPTdQ1jTLQKkHc37CtIZEcJ8pH+5CFZnI+ZfYwC/Oqfa/PVabYT7V9DKPhmqapGvh8N998c3GstqfUCog8xjmhul3rX0Spt3wWPY82NKswOem+tA+6mPWVY8E9DN/ZIsoKw8eOHSuOUW9pKzX1BKtynThxomtrWCXfK3UvxX00Q4R0bWX4u+63s4qENZYdppmt0VxnKIusKqMe4/hl1ZlpX7lu6Tgy9E91jFW/OP/U7vK9MqscyfHgehwxf11cvjYbY4wxxhhjjDHGmC3HPwIZY4wxxhhjjDHGrAD+EcgYY4wxxhhjjDFmBehNTqAsPpBxb1kMa1aWlHGXjLfWOPRHH320a9dKmUaU8dAau8lzGTuY5anQ608aV73suM4a2i/KlHHTGhfJzzqulFWthGBEOQ+yMuZZfhf2g/G22dzM4umHSlZ+k7HNGvtay98UUY4n9UN1kd+jTHXO8Jheg7HTWb6SrDwzZczxyM5bNhwHHX/Khvl22I4oy14y5jmizGfBmG3VAeZCeOGFF7q25hqp5YvRcxlbrzkdsnhuyi2LDx8StTUzK+udlUfluGjOAX5Pc2YR3juLZeec0XWRc0uP1fKzZetNn+GYc87q89DWZLkEOM917CgPXk9zzlCvNJ8b781rTJqvKqJ8ZtrhIeXnysjy6NT2shGlTlBXslLFWQ7BWl7JiHKeZLnssmO1e/WZbEw4F1966aWurTaT9o95CyNK28V1VtdPyi3L4UI5aT+oz7wv19mI0parDHUObnTfiH7LV5+Be9FDhw517f379xfncV3UHJFk165dXfvo0aPVa3Avu2/fvuK8Wh7GiHLeMTeRvsPqekomzXnYJzlmfeHz8D1D39M45pqHiTrB62leJ84X9knvxX0o98baR667ulei3n//+98vjtHmcM+evXPOg2GussYYY4wxxhhjjDFmKvwjkDHGGGOMMcYYY8wK0JtwMJK5dtdCMyJKly915aJbVuaGxuvXQoL0Xpl7Vs1NLyJ3Wa+Vhe+TO9801NyKs3AjHR+67ak7Xu17mYt9Fo5Xk+lQx39WspDLrERzrdzqRueuo67ttXCXzD7otdlHumlOE6o3qfvlUEJQaMsYmkn39YiI5557rmsfOXKkOFYLQ9AxoP7xWBZKp269tfP0GpmtHWpoyaRkdjQL6aDMKassdJnzR13UGfqThenyenov2o4slGiIMp10zVcbl4UA0XWcY6L6TKg7ej3OpSzciPMgC2dXPeXnodjMWZmm5HqNTAbzYAxhXrOg48qwyGxuMyyEYT4Rpb3i2DHUI6LUAYanqL3jZ30Hqb0j6PpJe5rNxyw0s89oX/mewDVI5c0xUztUC53Ve1E+vMaZM2eK8/g5k3EWypXtb7K1o69Mavs1LI4wLYjOe4Zo8ZjuN/guyTmhZeCfeeaZDe8bEfHss892bcpJ5xy/p+Gd/MzvbXWo+/B2UcYYY4wxxhhjjDFmavwjkDHGGGOMMcYYY8wK4B+BjDHGGGOMMcYYY1aAXuYEUmq5QSbNxRNRL4WYMct3IuaTq2Cr48CHQFbecNIx1vhbszXMoxTlNHl6zHzI8inNwwYxdp3Xz3LYZMxiA1aNLB9SVkZ1ljj0LFfepIylNPhmyZ57ljFR/Z107zSp3mf5bcae62ceTLpGel1cDJRHtj4xR0xW3j3LOcN7vfHGGxv+XcmuUetfRDl/9BpZrsWhwnGfdf/PdTJbF2tMKqtZGYusanBfwdx21JWIXMfOnTvXtWu/Iegx5oLS93/VK1KbI2q7s5xPZJHr52rutowxxhhjjDHGGGNWDP8IZIwxxhhjjDHGGLMCNOgjbcoAAASpSURBVIt0O2qa5oWIOB0R10TEiwu78cb0oQ8Ri+nHvrZtr53HhXomw4jV6se85fh6rM7YTcIQZWhdvJAhytG6WDJEGVoXL2SIcrQulgxRhtbFCxmiHK2LJUOUoXVxOX2YSI4L/RGou2nTPNy27V0Lv3HP+tCnfkxLX/rtfsxOX/rsfmyOvvTb/ZidvvTZ/dgcfem3+zE7femz+7E5+tJv92N2+tJn92Nz9KXffehHH/pAHA5mjDHGGGOMMcYYswL4RyBjjDHGGGOMMcaYFWBZPwJ9cUn3JX3oQ0R/+jEtfem3+zE7femz+7E5+tJv92N2+tJn92Nz9KXf7sfs9KXP7sfm6Eu/3Y/Z6Uuf3Y/N0Zd+96EffehDx1JyAhljjDHGGGOMMcaYxeJwMGOMMcYYY4wxxpgVYKE/AjVN80tN0zzRNM2TTdN8ZoH3/bOmaZ5vmuYI/ra9aZq/a5rmxNr/r15AP25smubvm6Y52jTN403T/M6y+rIZVlmOluGm72sZzollyXDt3pbjnLAuWoabvLflOCesi5bhJu9tOc4J66JluMl7W46T0LbtQv6LiEsi4mREHIyISyPisYi4bUH3/m8R8b6IOIK/fT4iPrPW/kxE/O8F9OO6iHjfWvuKiDgeEbctoy+Wo2VoGVqGluPqytEyHL4MLcdxyNEyHL4MLcdxyNEyHL4MLccp+rhAgXwwIr6Oz5+NiM8u8P77ZTI8ERHXQVBPLHzwI/46Ij7ah75YjpahZWgZWo6rJUfLcPgytBzHIUfLcPgytBzHIUfLcPgytBwn+2+R4WA3RMQZfD679rdlsatt2/MREWv/37nImzdNsz8i7oyIB5fdlymxHNewDOeGZTg9fZNhhOU4C32To2U4PX2TYYTlOAt9k6NlOD19k2GE5TgLfZOjZTg9fZNhhOV4AYv8EajZ4G/tAu/fG5qm2RYRX4mIT7Vt+8qy+zMllmNYhmPAMhwHluPwsQzHgeU4fCzDcWA5Dh/LcBz0WY6L/BHobETciM97IuLcAu+vPNc0zXUREWv/f34RN22a5q3xk8nwl23b/tUy+zIjKy9Hy3DuWIbT0zcZRliOs9A3OVqG09M3GUZYjrPQNzlahtPTNxlGWI6z0Dc5WobT0zcZRliOF7DIH4EeioibmqY50DTNpRHx6xHx1QXeX/lqRNy31r4vfhKrt6U0TdNExJ9GxNG2bf94mX3ZBCstR8twS7AMp6dvMoywHGehb3K0DKenbzKMsBxnoW9ytAynp28yjLAcZ6FvcrQMp6dvMoywHC9kwUmRPhY/yY59MiI+t8D7fjkizkfEj+Inv07+RkTsiIhvRMSJtf9vX0A/PhQ/cYf7bkQ8uvbfx5bRF8vRMrQMLUPLcfn/WRctQ8uxH/9ZFy1Dy7Ef/1kXLUPLcev/a9Y6aowxxhhjjDHGGGNGzCLDwYwxxhhjjDHGGGPMkvCPQMYYY4wxxhhjjDErgH8EMsYYY4wxxhhjjFkB/COQMcYYY4wxxhhjzArgH4GMMcYYY4wxxhhjVgD/CGSMMcYYY4wxxhizAvhHIGOMMcYYY4wxxpgVwD8CGWOMMcYYY4wxxqwA/x//NyG8YUBSMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x144 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get weights\n",
    "weights = sess.run(W)\n",
    "\n",
    "fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
    "\n",
    "for digit in range(10):\n",
    "    ax[digit].imshow(weights[:,digit].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close session to finish\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Full Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire model, with the complete model definition, training, and evaluation (but minus the weights visualization), is below. Note the slight difference when calculating the softmax; this is done for numerical stability purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 668.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.914900004863739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import trange\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Import data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(x, W) + b\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y)) # more stable numerically than what we did before\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# Create a Session object, initialize all variables\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Train\n",
    "for _ in trange(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "# Test trained model\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Test accuracy: {0}'.format(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The accuracy from the full version directly above might return a slightly different test accuracy from the step-by-step version we first went through. This is because mnist.train.next_batch by default shuffles the order of the training data, so we're seeing the data in a different order. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-class Exercise: Multi-layer Perceptron\n",
    "\n",
    "Build a 2-layer Multi-layer Perception (MLP) for MNIST digit classfication. Feel free to play around with the model architecture and see how the training time/performance changes, but to begin, try the following:\n",
    "\n",
    "Image (784 dimensions) -> fully connected layer (500 hidden units)  -> nonlinearity (ReLU) -> fully connected layer (100 hidden units) -> nonlinearity (ReLU) -> fully connected (10 hidden units) -> softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 168.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9659000039100647\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "import tensorflow as tf\n",
    "from tqdm import trange\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Import data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Create the model\n",
    "# If you use zeros for the W's and b's, your accuracy is as good as guessing\n",
    "# Better with weight matrices using tf.truncated_normal([shape], stdev=0.1)\n",
    "#         and bias vectors using tf.constant(0.1, shape=[500])\n",
    "\n",
    "hiddenUnits1 = 500\n",
    "hiddenUnits2 = 150\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # input\n",
    "W1 = tf.Variable(tf.truncated_normal([784, hiddenUnits1], stddev=0.1))\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=[hiddenUnits1]))\n",
    "h1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([hiddenUnits1, hiddenUnits2], stddev=0.1))\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[hiddenUnits2]))\n",
    "h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([hiddenUnits2, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "y = tf.matmul(h2, W3) + b3\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y)) # more stable numerically than what we did before\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# Create a Session object, initialize all variables\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Train\n",
    "for _ in trange(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "# Test trained model\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Test accuracy: {0}'.format(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})))\n",
    "\n",
    "sess.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Questions/Exercises (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many learnable weight parameters does your MLP have? How does that compare with the logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Try making some changes to your MLP architecture. How sensitive is your MLP's accuracy to the number of layers (depth) or number of units per layer (width)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Acknowledgment: Material partially adapted from the TensorFlow tutorial: https://www.tensorflow.org/get_started/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
